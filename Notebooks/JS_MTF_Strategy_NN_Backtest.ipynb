{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi timeframe strategy development\n",
    "\n",
    "This notebook will show how to develop strategy using multiple timeframes with MLP Classificator.\n",
    "\n",
    "## Steps:\n",
    "1) Importing smallest dataframe, split to train and test resample to higher.\n",
    "2) Featuring dataframe with indicators and other valuables informations (predictors).\n",
    "3) Scale data, import MLPclassificator, create model, fit and predict.\n",
    "4) Do steps 2 and 3 for every timeframe.\n",
    "5) Merge predictions from higher tf to main one(smallest).\n",
    "6) Vectorised backtest of predictions\n",
    "7) Event based backtest\n",
    "8) Adjusting sl, tp, managing trades to train set\n",
    "\n",
    "### If there are good results in train set:\n",
    "\n",
    "9) Backtest on test set(event based backtest with all params).\n",
    "\n",
    "### Good results on test set?\n",
    "\n",
    "10) Code strategy for MT5.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import, split and resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 100393 entries, 2019-12-09 05:45:00 to 2023-12-19 18:15:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   open    100393 non-null  float64\n",
      " 1   high    100393 non-null  float64\n",
      " 2   low     100393 non-null  float64\n",
      " 3   close   100393 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ReadyData/EURUSD_2018_2023_15m.csv',index_col=0,parse_dates=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 70275 entries, 2019-12-09 05:45:00 to 2022-10-04 22:45:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    70275 non-null  float64\n",
      " 1   high    70275 non-null  float64\n",
      " 2   low     70275 non-null  float64\n",
      " 3   close   70275 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 2.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 30118 entries, 2022-10-04 23:00:00 to 2023-12-19 18:15:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    30118 non-null  float64\n",
      " 1   high    30118 non-null  float64\n",
      " 2   low     30118 non-null  float64\n",
      " 3   close   30118 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "split = int(len(df) * 0.7)\n",
    "\n",
    "train = df[:split]\n",
    "test = df[split:]\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1df = resample_dataframe(train,'60T')\n",
    "h4df = resample_dataframe(train,'240T')\n",
    "d1df = resample_dataframe(train,'1D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Featuring datas and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df 15m tf\n",
    "df['ret1'] = df['close'].pct_change()\n",
    "df['ret5'] = df.ret1.rolling(5).sum()\n",
    "df['std5'] = df.ret1.rolling(5).std()\n",
    "df['H-L'] = df['high'] - df['low']\n",
    "df['O-C'] = df['close'] - df['open']\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# For h1df\n",
    "h1df['ret1'] = h1df['close'].pct_change()\n",
    "h1df['ret5'] = h1df['ret1'].rolling(5).sum()\n",
    "h1df['std5'] = h1df['ret1'].rolling(5).std()\n",
    "h1df['H-L'] = h1df['high'] - h1df['low']\n",
    "h1df['O-C'] = h1df['close'] - h1df['open']\n",
    "h1df.dropna(inplace=True)\n",
    "\n",
    "# For h4df\n",
    "h4df['ret1'] = h4df['close'].pct_change()\n",
    "h4df['ret5'] = h4df['ret1'].rolling(5).sum()\n",
    "h4df['std5'] = h4df['ret1'].rolling(5).std()\n",
    "h4df['H-L'] = h4df['high'] - h4df['low']\n",
    "h4df['O-C'] = h4df['close'] - h4df['open']\n",
    "h4df.dropna(inplace=True)\n",
    "\n",
    "# For d1df\n",
    "d1df['ret1'] = d1df['close'].pct_change()\n",
    "d1df['ret5'] = d1df['ret1'].rolling(5).sum()\n",
    "d1df['std5'] = d1df['ret1'].rolling(5).std()\n",
    "d1df['H-L'] = d1df['high'] - d1df['low']\n",
    "d1df['O-C'] = d1df['close'] - d1df['open']\n",
    "d1df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets\n",
    "df['retFut1'] = df.ret1.shift(-1)\n",
    "\n",
    "# For h1df\n",
    "h1df['retFut1'] = h1df['ret1'].shift(-1)\n",
    "\n",
    "# For h4df\n",
    "h4df['retFut1'] = h4df['ret1'].shift(-1)\n",
    "\n",
    "# For d1df\n",
    "d1df['retFut1'] = d1df['ret1'].shift(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale data, create model,fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df[['H-L', 'O-C', 'ret5', 'std5']]\n",
    "features_h1df = h1df[['H-L', 'O-C', 'ret5', 'std5']]\n",
    "features_h4df = h4df[['H-L', 'O-C', 'ret5', 'std5']]\n",
    "features_d1df = d1df[['H-L', 'O-C', 'ret5', 'std5']]\n",
    "\n",
    "target_df = np.where(df.retFut1 > 0.0, 1, 0)\n",
    "target_h1df = np.where(h1df.retFut1 > 0.0, 1, 0)\n",
    "target_h4df = np.where(h4df.retFut1 > 0.0, 1, 0)\n",
    "target_d1df = np.where(d1df.retFut1 > 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_length = int(len(df)*0.80)\n",
    "\n",
    "X_train_df = features_df[:train_length]\n",
    "X_test_df = features_df[train_length:]\n",
    "\n",
    "y_train_df = target_df[:train_length]\n",
    "y_test_df = target_df[train_length:]\n",
    "\n",
    "\n",
    "train_length_h1 = int(len(h1df)*0.80)\n",
    "\n",
    "# Splitting h1df into training and testing sets\n",
    "X_train_h1df = h1df[:train_length_h1]\n",
    "X_test_h1df = h1df[train_length_h1:]\n",
    "\n",
    "\n",
    "train_length_h4 = int(len(h4df)*0.80)\n",
    "\n",
    "# Splitting h4df into training and testing sets\n",
    "X_train_h4df = h4df[:train_length_h4]\n",
    "X_test_h4df = h4df[train_length_h4:]\n",
    "\n",
    "\n",
    "train_length_d1 = int(len(d1df)*0.80)\n",
    "\n",
    "# Splitting d1df into training and testing sets\n",
    "X_train_d1df = d1df[:train_length_d1]\n",
    "X_test_d1df = d1df[train_length_d1:]\n",
    "\n",
    "# Assuming corresponding target variables for each dataframe are also sliced similarly\n",
    "y_train_h1df = target_h1df[:train_length_h1]\n",
    "y_test_h1df = target_h1df[train_length_h1:]\n",
    "\n",
    "y_train_h4df = target_h4df[:train_length_h4]\n",
    "y_test_h4df = target_h4df[train_length_h4:]\n",
    "\n",
    "y_train_d1df = target_d1df[:train_length_d1]\n",
    "y_test_d1df = target_d1df[train_length_d1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# Create the scaler model using train data\n",
    "scaler.fit(X_train_df)\n",
    "\n",
    "# Transform the training and test data using the scaler model created above\n",
    "X_train = scaler.transform(X_train_df)\n",
    "X_test = scaler.transform(X_test_df)\n",
    "\n",
    "\n",
    "# Create the scaler model using train data for h1df\n",
    "scaler.fit(X_train_h1df)\n",
    "X_train_h1df_scaled = scaler.transform(X_train_h1df)\n",
    "X_test_h1df_scaled = scaler.transform(X_test_h1df)\n",
    "\n",
    "# Create the scaler model using train data for h4df\n",
    "scaler.fit(X_train_h4df)\n",
    "X_train_h4df_scaled = scaler.transform(X_train_h4df)\n",
    "X_test_h4df_scaled = scaler.transform(X_test_h4df)\n",
    "\n",
    "# Create the scaler model using train data for d1df\n",
    "scaler.fit(X_train_d1df)\n",
    "X_train_d1df_scaled = scaler.transform(X_train_d1df)\n",
    "X_test_d1df_scaled = scaler.transform(X_test_d1df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# Create the MLPClassifier model\n",
    "mlp_df = MLPClassifier(activation='logistic', hidden_layer_sizes=(\n",
    "    5), random_state=seed, solver='sgd')\n",
    "\n",
    "\n",
    "# Create MLPClassifier model for h1df\n",
    "mlp_h1df = MLPClassifier(activation='logistic', hidden_layer_sizes=(5), random_state=seed, solver='sgd')\n",
    "\n",
    "# Create MLPClassifier model for h4df\n",
    "mlp_h4df = MLPClassifier(activation='logistic', hidden_layer_sizes=(5), random_state=seed, solver='sgd')\n",
    "\n",
    "# Create MLPClassifier model for d1df\n",
    "mlp_d1df = MLPClassifier(activation='logistic', hidden_layer_sizes=(5), random_state=seed, solver='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakub\\anaconda3\\envs\\Algo_vibes\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jakub\\anaconda3\\envs\\Algo_vibes\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jakub\\anaconda3\\envs\\Algo_vibes\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=5, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=5, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=5, random_state=42,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_df.fit(X_train_df, y_train_df)\n",
    "\n",
    "# Training MLPClassifier model for h1df\n",
    "mlp_h1df.fit(X_train_h1df_scaled, y_train_h1df)\n",
    "\n",
    "# Training MLPClassifier model for h4df\n",
    "mlp_h4df.fit(X_train_h4df_scaled, y_train_h4df)\n",
    "\n",
    "# Training MLPClassifier model for d1df\n",
    "mlp_d1df.fit(X_train_d1df_scaled, y_train_d1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_signal'] = mlp_df.predict(X)\n",
    "data['strategy_returns_nn'] = data.retFut1 * data.predicted_signal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algo_vibes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
